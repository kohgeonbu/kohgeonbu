{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPK5ymQw7Ru8feitIrXHW4O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kohgeonbu/kohgeonbu/blob/main/annomal_mix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvUR_lM36udi",
        "outputId": "bcd83ba0-2520-4c4b-9e6e-04bf5199f541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train bg: 100%|██████████| 100/100 [01:00<00:00,  1.66it/s]\n",
            "test bg: 100%|██████████| 25/25 [00:04<00:00,  5.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done! Check: /content/drive/MyDrive/mixed_out\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# 1) 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2) 패키지 설치\n",
        "!pip -q install numpy librosa soundfile tqdm\n",
        "\n",
        "# 3) 믹서 코드(간단 버전)\n",
        "import os, csv, random, numpy as np, librosa, soundfile as sf\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_mono(path, target_sr=None):\n",
        "    x, sr = librosa.load(path, sr=target_sr, mono=True)\n",
        "    return x.astype(np.float32), (target_sr or sr)\n",
        "\n",
        "def rms(x): return float(np.sqrt(np.mean(np.square(x))+1e-12))\n",
        "\n",
        "def apply_fade(x, sr, fade_ms=15.0):\n",
        "    n=len(x); k=int(sr*fade_ms/1000.0)\n",
        "    if k<=0 or k*2>=n: return x\n",
        "    w_in=np.linspace(0,1,k,dtype=np.float32); w_out=w_in[::-1]\n",
        "    y=x.copy(); y[:k]*=w_in; y[-k:]*=w_out; return y\n",
        "\n",
        "def normalize_peak(x, target_dbfs=-1.0):\n",
        "    peak=float(np.max(np.abs(x))+1e-12); limit=10**(target_dbfs/20.0)\n",
        "    return x*(limit/peak) if peak>limit else x\n",
        "\n",
        "def scale_to_snr(bg_seg, fg_seg, snr_db):\n",
        "    p_bg=rms(bg_seg)**2; p_fg=rms(fg_seg)**2\n",
        "    if p_bg<1e-12 or p_fg<1e-12: return np.zeros_like(fg_seg)\n",
        "    target_p_fg=p_bg/(10**(snr_db/10.0))\n",
        "    scale=np.sqrt(max(target_p_fg,1e-12)/(p_fg+1e-12))\n",
        "    return fg_seg*scale\n",
        "\n",
        "def collect_audio_files(root, exts=(\".wav\",\".flac\",\".mp3\")):\n",
        "    outs=[]\n",
        "    for dp,_,fns in os.walk(root):\n",
        "        for fn in fns:\n",
        "            if fn.lower().endswith(exts): outs.append(os.path.join(dp,fn))\n",
        "    outs.sort(); return outs\n",
        "\n",
        "def mix_dataset(bg_dir, anom_dir, out_dir, target_sr=16000,\n",
        "                snr_list=(0,3,6,10), mix_per_bg=2, onset_min=0.2, onset_max=6.0,\n",
        "                split_ratio=0.8, do_split=True, seed=42):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    meta_path=os.path.join(out_dir,\"metadata.csv\")\n",
        "    rng=random.Random(seed); np.random.seed(seed)\n",
        "\n",
        "    bg_files=collect_audio_files(bg_dir); anom_files=collect_audio_files(anom_dir)\n",
        "    assert bg_files, f\"No background files in {bg_dir}\"\n",
        "    assert anom_files, f\"No anomaly files in {anom_dir}\"\n",
        "\n",
        "    def split(lst, ratio):\n",
        "        idx=list(range(len(lst))); rng.shuffle(idx)\n",
        "        cut=int(len(lst)*ratio); return [lst[i] for i in idx[:cut]], [lst[i] for i in idx[cut:]]\n",
        "\n",
        "    subsets=[(\"all\", bg_files)]\n",
        "    if do_split:\n",
        "        tr, te = split(bg_files, split_ratio)\n",
        "        subsets=[(\"train\", tr), (\"test\", te)]\n",
        "\n",
        "    with open(meta_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        wr=csv.writer(f)\n",
        "        wr.writerow([\"subset\",\"mixed_path\",\"bg_file\",\"anom_file\",\"sr\",\"snr_db\",\"onset_sec\",\"duration_sec\",\"label\"])\n",
        "\n",
        "        for subset, bgs in subsets:\n",
        "            subdir=os.path.join(out_dir, subset); os.makedirs(subdir, exist_ok=True)\n",
        "            for bgp in tqdm(bgs, desc=f\"{subset} bg\"):\n",
        "                try:\n",
        "                    bg, sr = load_mono(bgp, target_sr=target_sr)\n",
        "                except Exception as e:\n",
        "                    print(\"[WARN] skip bg:\", bgp, e); continue\n",
        "\n",
        "                for _ in range(mix_per_bg):\n",
        "                    ap = rng.choice(anom_files)\n",
        "                    try:\n",
        "                        fg, _ = load_mono(ap, target_sr=sr)\n",
        "                    except Exception as e:\n",
        "                        print(\"[WARN] skip fg:\", ap, e); continue\n",
        "\n",
        "                    max_onset = max(onset_min, min(onset_max, (len(bg)/sr)-0.2))\n",
        "                    onset_sec = rng.uniform(onset_min, max_onset)\n",
        "                    onset = int(onset_sec*sr)\n",
        "                    avail = max(1, len(bg)-onset)\n",
        "                    fg_seg = apply_fade(fg[:avail], sr, fade_ms=15.0)\n",
        "                    bg_seg = bg[onset:onset+len(fg_seg)]\n",
        "                    snr_db = rng.choice(snr_list)\n",
        "                    fg_scaled = scale_to_snr(bg_seg, fg_seg, snr_db)\n",
        "                    y = bg.copy(); y[onset:onset+len(fg_scaled)] = bg_seg + fg_scaled\n",
        "                    y = normalize_peak(y, -1.0)\n",
        "\n",
        "                    bg_base=os.path.splitext(os.path.basename(bgp))[0]\n",
        "                    fg_base=os.path.splitext(os.path.basename(ap))[0]\n",
        "                    out_name=f\"{bg_base}__{fg_base}__snr{snr_db}dB__on{onset_sec:.2f}.wav\"\n",
        "                    out_path=os.path.join(subdir, out_name)\n",
        "                    sf.write(out_path, y, sr, subtype=\"PCM_16\")\n",
        "\n",
        "                    wr.writerow([subset,out_path,bgp,ap,sr,snr_db,round(onset_sec,3),round(len(fg_scaled)/sr,3),1])\n",
        "\n",
        "# 4) 당신의 드라이브 경로(요청대로 고정 세팅)\n",
        "bg_dir   = \"/content/drive/MyDrive/normal\"\n",
        "anom_dir = \"/content/drive/MyDrive/abnormal\"\n",
        "out_dir  = \"/content/drive/MyDrive/mixed_out\"\n",
        "\n",
        "# 5) 실행(필요하면 파라미터만 바꿔주세요)\n",
        "mix_dataset(\n",
        "    bg_dir, anom_dir, out_dir,\n",
        "    target_sr=16000,          # 원본 SR 유지 원하면 48000 등 원하는 값으로 바꿔도 OK(현재는 16k 권장)\n",
        "    snr_list=(0,3,6,10),\n",
        "    mix_per_bg=2,             # 정상 1개당 2개 생성\n",
        "    onset_min=0.2, onset_max=6.0,\n",
        "    split_ratio=0.8, do_split=True, seed=42\n",
        ")\n",
        "\n",
        "print(\"Done! Check:\", out_dir)\n"
      ]
    }
  ]
}